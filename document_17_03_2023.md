# ECIQC document (17th March 2023)

This is a document for the ECIQC project. It summarises the work done by the 2020 and 2021 cohort, features added by the 2022 cohort (October 2022 to March 2023), work plans for the second half of the year.

### Contents
* Background
* Work by the 2020 and 2021 cohort 
* New features by the 2022 cohort
* Work plans
* Details of different branches and issues

### New features by the 2022 cohort
When we took on this project, we had only a vague idea on how the pipeline actually work, and none of us had any experience working with c++! A lot of ideas went around on what we should do! As time went by, with the help of Martin, Chris, Ian, Julia and Emmanuel, we had a clear road map:

> --> create a logging system for each part
> 
> --> build up the whole pipeline
>    
> --> test the whole pipeline under different cases
>    
> --> debug and improve

Now let's dive deep into each part, and see what we've already done.

#### Step1: Create a logging system

Logging is an important part in modern software engineering, and it helps us get familiar with the code. So we started with adding the logger. Martin taught us how to set up the [DCMTK logger file](./src/logging.cpp). Then we were able to set up the logger by writing
```
set_root_logging("./result/pipeline_root_test.log", true);
```

in the [main function](./exe/qctool.cpp). After that, we could simply add the logging in any part of the codes we were interested in by writing something like
```
OFLOG_ERROR(get_logger(), "Some checks failed!");
```

The `get_logger()` is a function in the [DCMTK logger file](./src/logging.cpp). You can put in any information as the second argument. **Remember** to `#include "logging.hpp"` when you intend to using logging. Also, DTMCK logging system has [five levels of logging severity](https://support.dcmtk.org/docs-dcmrt/classOFLogger.html).

Here's an example of our logger file afterwards (line 1-10).
>INFO - Receiver starts to work!
>
>SCP Port: 11112
>
>title: SCP
>
>INFO - Parser start to work. We're in the processing pipeline!
>
>DEBUG - The key we're working on: (0008,0060)
>
>DEBUG - Process description: "check if modality is MR and manufacturer is 'SIEMENS' or 'HITACHI':"
>
>ERROR - Some checks failed!
>
>INFO - Parser worked finished!
>
>INFO - The parser has finished! Sent to quarantine!

In applications, we need to create a **separate** logger file for **each** image, and one logging file for the pipeline. This is work in progress. Please refer to #73, and the relevant section in `Work plans` and  `Details of different branches and issues` for more information.

#### Step2: build up the whole pipeline
Before we took up this project, different parts of the pipeline ([sender](./src/communication/Sender.cpp), [receiver](./src/communication/Receiver.cpp), [parser](./src/parsing/Parser.cpp),) has been done, and the unit tests works well. Based on that, we need to build up the whole pipeline, and start the pipeline using the executable file. To achieve that, we finish writing the [conductor](./src/Conductor.cpp), and after `cmake ..` and `make`, we can simple write the following code to start the pipeline:

```
./build/exe/qctool --config-file='./schema/PipelineCase.json'
```
The config file needs to be specified to tell the pipeline what to do (e.g. anonymise the patient name, birthday, etc), which port number to listen at and to send the postprocessed files.

The pipeline cannot work on its own. It needs to listen to *someone* to receiver the files, and send the postprocessed files to *someone* who is listening. There are two choices. The first choice is to use the [DCMTK SCP](https://support.dcmtk.org/docs/storescp.html) and [DCMTK SCU](https://support.dcmtk.org/docs/storescu.html) executable files. The second choice is to use [pynetdicom](https://github.com/pydicom/pynetdicom) to manually set up these executable files. Both approaches are wrapped up in the pipelinetest_main.py (./pipelinetest_main.py) file, and we can use the argument `use_pynetdicom` to select the 

### Work plans
#### Plan1: Modifying the logging system
Assignee: Ola
Expected finishing time: before June.
Description: Please see #73 for more information. Briefly, we need separate logging for each image, and another logging file for the pipeline. Also, there are many annoying print-outs in different files. They might be useful when debugging, but should be cleared now.
Branch: i73-logging

### Details of different branches and issues
#### #73: 
